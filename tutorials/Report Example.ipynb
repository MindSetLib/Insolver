{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8838acda",
   "metadata": {},
   "source": [
    "# Report Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb997a",
   "metadata": {},
   "source": [
    "Let's see how we can create html report with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f8bc9",
   "metadata": {},
   "source": [
    "## Import libraries and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44805c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import key libraries we potentially need to start this pipeline.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import hp\n",
    "from sklearn.metrics import mean_gamma_deviance, mean_squared_error\n",
    "\n",
    "# InsolverDataFrame is a special class based on pandas data frame with additional properties, which allow you to use additional methods for data frames. We will look at these methods later.\n",
    "from insolver import InsolverDataFrame\n",
    "\n",
    "# Insolver transformation is used for data transformation especially during inference.\n",
    "# After you experiment with dataset, you can register your own transformations and then use them anywhere. Also, it is extremely useful during model implementation.\n",
    "from insolver.transforms import (\n",
    "    InsolverTransform,\n",
    "    TransformExp,\n",
    "    TransformAge,\n",
    "    TransformMapValues,\n",
    "    TransformPolynomizer,\n",
    "    TransformAgeGender,\n",
    ")\n",
    "\n",
    "# Special wrappers allow you to create models with simple interfaces,\n",
    "# here we import special GLM models which are very often used in insurance, GBM models which became very popular last year and Trivial models to compare our model with trivial ones.\n",
    "\n",
    "from insolver.wrappers import InsolverGLMWrapper, InsolverGBMWrapper, InsolverTrivialWrapper, InsolverRFWrapper\n",
    "from insolver.model_tools import ModelMetricsCompare, deviance_gamma, download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3c400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set up user transformations\n",
    "class TransformSocioCateg:\n",
    "    def __init__(self, column_socio_categ):\n",
    "        self.priority = 0\n",
    "        self.column_socio_categ = column_socio_categ\n",
    "\n",
    "    def __call__(self, df):\n",
    "        df[self.column_socio_categ] = df[self.column_socio_categ].str.slice(0, 4)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51c1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renew experience function\n",
    "class TransformExp:\n",
    "    def __init__(self, column_driver_minexp, exp_max=52):\n",
    "        self.priority = 1\n",
    "        self.column_driver_minexp = column_driver_minexp\n",
    "        self.exp_max = exp_max\n",
    "\n",
    "    @staticmethod\n",
    "    def _exp(exp, exp_max):\n",
    "        import pandas as pd\n",
    "\n",
    "        if pd.isnull(exp):\n",
    "            exp = None\n",
    "        elif exp < 0:\n",
    "            exp = None\n",
    "        else:\n",
    "            exp = exp // 12\n",
    "        if exp > exp_max:\n",
    "            exp = exp_max\n",
    "        return exp\n",
    "\n",
    "    def __call__(self, df):\n",
    "        df[self.column_driver_minexp] = df[self.column_driver_minexp].apply(self._exp, args=(self.exp_max,))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cac5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data to pandas dataframe\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "download_dataset('freMPL-R')\n",
    "df = pd.read_csv('./datasets/freMPL-R.csv', low_memory=False)\n",
    "df = df[df.Dataset.isin([5, 6, 7, 8, 9])]\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df[df.ClaimAmount > 0]\n",
    "\n",
    "# Transfer our dataframe to InsolverDataFrame to get additional possibilities for analytics and dataframe transforms.\n",
    "InsDataFrame = InsolverDataFrame(df)\n",
    "\n",
    "# After that we can combine all transformations into one one object\n",
    "InsTransforms = InsolverTransform(\n",
    "    InsDataFrame,\n",
    "    [\n",
    "        TransformSocioCateg('SocioCateg'),\n",
    "        TransformAge('DrivAge', 18, 75),\n",
    "        TransformExp('LicAge', 57),\n",
    "        TransformMapValues('Gender', {'Male': 0, 'Female': 1}),\n",
    "        TransformMapValues('MariStat', {'Other': 0, 'Alone': 1}),\n",
    "        TransformAgeGender('DrivAge', 'Gender', 'Age_m', 'Age_f', age_default=18, gender_male=0, gender_female=1),\n",
    "        TransformPolynomizer('Age_m'),\n",
    "        TransformPolynomizer('Age_f'),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Now we are ready to implement transformations\n",
    "InsTransforms.ins_transform()\n",
    "\n",
    "# Classical train test split of transformations\n",
    "train, valid, test = InsTransforms.split_frame(val_size=0.15, test_size=0.15, random_state=0, shuffle=True)\n",
    "\n",
    "# Lets take features and target\n",
    "features = [\n",
    "    'LicAge',\n",
    "    'Gender',\n",
    "    'MariStat',\n",
    "    'DrivAge',\n",
    "    'HasKmLimit',\n",
    "    'BonusMalus',\n",
    "    'RiskArea',\n",
    "    'Age_m',\n",
    "    'Age_f',\n",
    "    'Age_m_2',\n",
    "    'Age_f_2',\n",
    "]\n",
    "target = 'ClaimAmount'\n",
    "\n",
    "# Split on train, validation and test data\n",
    "x_train, y_train = train[features], train[target]\n",
    "x_valid, y_valid = valid[features], valid[target]\n",
    "x_test, y_test = test[features], test[target]\n",
    "offset_train = train['Exposure']\n",
    "offset_valid = valid['Exposure']\n",
    "offset_test = test['Exposure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284572f0",
   "metadata": {},
   "source": [
    "## Report creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bd45e",
   "metadata": {},
   "source": [
    "Let's train some models and see how we can create reports for them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fa5e9",
   "metadata": {},
   "source": [
    "To create a report we need `insolver.report.Report` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f20774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insolver.report import Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c72d0f",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "irf = InsolverRFWrapper(backend='sklearn', task='reg')\n",
    "irf.fit(x_train, y_train)\n",
    "predict_rf = irf.predict(x_test)\n",
    "predict_rf_train = irf.predict(x_train)\n",
    "predict_rf_test = irf.predict(x_test)\n",
    "\n",
    "# To use Report we need to pass as parameters\n",
    "# model:             model instanse\n",
    "# task:              'reg' for regression and 'class' for classification\n",
    "# X_train, y_train:  train dataset\n",
    "# predicted_train:   model predictions for train dataset\n",
    "# X_test, y_test:    test dataset\n",
    "# predicted_test:    model predictions for test dataset\n",
    "\n",
    "r = Report(\n",
    "    model=irf,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_rf_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_rf_test),\n",
    ")\n",
    "\n",
    "# To create an html file we use `Report.to_html()` method\n",
    "# Parameters are:\n",
    "# path:        existing directory to save report (default '.')\n",
    "# report_name: name of created report directory (default 'report')\n",
    "\n",
    "r.to_html(report_name='0_random_forest_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51366dff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa215da",
   "metadata": {},
   "source": [
    "Now you can open the `report.html` from the directory where it was created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c303e67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032648c",
   "metadata": {},
   "source": [
    "Same way you can create report for other models and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec823cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iglm_h2o\n",
    "iglm = InsolverGLMWrapper(backend='h2o', family='gamma', link='log')\n",
    "iglm.fit(\n",
    "    x_train, y_train, sample_weight=offset_train, X_valid=x_valid, y_valid=y_valid, sample_weight_valid=offset_valid\n",
    ")\n",
    "predict_glm_train = iglm.predict(x_train, sample_weight=offset_train)\n",
    "predict_glm_test = iglm.predict(x_test, sample_weight=offset_test)\n",
    "\n",
    "r = Report(\n",
    "    model=iglm,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_glm_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_glm_test),\n",
    ")\n",
    "r.to_html(report_name='1_glm_h2o_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a38fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iglm_sklearn\n",
    "iglm2 = InsolverGLMWrapper(backend='sklearn', family='gamma', link='log', standardize=True)\n",
    "iglm2.fit(x_train, y_train, sample_weight=offset_train)\n",
    "predict_glm2_train = iglm2.predict(x_train, sample_weight=offset_train)\n",
    "predict_glm2_test = iglm2.predict(x_test, sample_weight=offset_test)\n",
    "\n",
    "r = Report(\n",
    "    model=iglm2,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_glm2_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_glm2_test),\n",
    ")\n",
    "r.to_html(report_name='2_glm_sklearn_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# igbm_xgboost\n",
    "igbm = InsolverGBMWrapper(backend='xgboost', task='reg', n_estimators=100, objective='gamma', tree_method='hist')\n",
    "igbm.fit(x_train, y_train, sample_weight=offset_train)\n",
    "predict_gbm_train = igbm.predict(x_train)\n",
    "predict_gbm_test = igbm.predict(x_test)\n",
    "\n",
    "r = Report(\n",
    "    model=igbm,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_gbm_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_gbm_test),\n",
    ")\n",
    "r.to_html(report_name='3_gbm_xgboost_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd57a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# igbm_lightgbm\n",
    "igbm2 = InsolverGBMWrapper(\n",
    "    backend='lightgbm', task='reg', n_estimators=100, objective='gamma', metric='gamma_deviance', boosting_type='goss'\n",
    ")\n",
    "igbm2.fit(x_train, y_train, sample_weight=offset_train)\n",
    "predict_gbm2_train = igbm2.predict(x_train)\n",
    "predict_gbm2_test = igbm2.predict(x_test)\n",
    "\n",
    "r = Report(\n",
    "    model=igbm2,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_gbm2_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_gbm2_test),\n",
    ")\n",
    "r.to_html(report_name='4_gbm_lightgbm_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# igbm3\n",
    "igbm3 = InsolverGBMWrapper(backend='catboost', task='reg', n_estimators=100, objective='gamma', silent=True)\n",
    "igbm3.fit(x_train, y_train, sample_weight=offset_train)\n",
    "predict_gbm3_train = igbm3.predict(x_train)\n",
    "predict_gbm3_test = igbm3.predict(x_test)\n",
    "\n",
    "r = Report(\n",
    "    model=igbm3,\n",
    "    task='reg',\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    predicted_train=pd.Series(predict_gbm3_train),\n",
    "    X_test=x_test,\n",
    "    y_test=y_test,\n",
    "    predicted_test=pd.Series(predict_gbm3_test),\n",
    ")\n",
    "r.to_html(report_name='5_gbm_catboost_report')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
